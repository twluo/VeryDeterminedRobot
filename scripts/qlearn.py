from std_msgs.msg import String, Boolfrom cse_190_assi_3.msg import PolicyListimport copyclass Qs(object):    def __init__(self):        self.obType = None        self.reward = None        self.qNSWE = [0.0]*4    def __repr__(self):        val, a = self.maxQ()        if a == None:            a = "_"        return "%.3f %s" % (val, a[0])    def copy(self, qold):        return copy.deepcopy(self)    def getType(self):        return self.obType    def setReward(self, reward):        self.reward = reward    def getReward(self):        return self.reward    def maxQ(self):        if self.obType != None:            return self.reward, None        assert(len(self.qNSWE) == 4)        assert(self.qNSWE[0] != None)        assert(self.qNSWE[1] != None)        assert(self.qNSWE[2] != None)        assert(self.qNSWE[3] != None)        qAndA = zip(self.qNSWE, ['N', 'S', 'W', 'E'])        q, action = max(qAndA)        return q, action    def setGridProperties(self, gridProperty):        if gridProperty == "PIT":            self.obType = "PIT"        elif gridProperty == "GOAL":            self.obType = "GOAL"        elif gridProperty == "WALL":            self.obType = "WALL"        else:            self.obType = Noneclass QLearner(object):    def __init__(self, config):        self.config = config        self.prevgrid = None        self.currstate = None        self.grid = self.gridConstructor()        self.iteration_count = 0    def northSouthWestEast(self, row, col):        """Returns the possible up down left rights"""        to_return = dict()        to_return["N"] = [row - 1, col]        to_return["S"] = [row + 1, col]        to_return["W"] = [row, col - 1]        to_return["E"] = [row, col + 1]        return dict(to_return)    def gridConstructor(self):        """Constructs the grid"""        config = self.config        height, width = config["map_size"]        grid = list()        for r in xrange(height):            column = list()            for w in xrange(width):                toAdd = Qs()                if   [r, w] in config["pits"]:                    toAdd.setGridProperties("PIT")                    toAdd.setReward(config["reward_for_falling_in_pit"])                elif [r, w] == config["goal"]:                    toAdd.setGridProperties("GOAL")                    toAdd.setReward(config["reward_for_reaching_goal"])                elif [r, w] in config["walls"]:                    toAdd.setGridProperties("WALL")                    toAdd.setReward(config["reward_for_hitting_wall"])                else:                    toAdd.setGridProperties("none")                    toAdd.setReward(config["reward_for_each_step"])                column.append(toAdd)            grid.append(column)        return grid    def renameThis(self):        """Returns boolean of whether or not it converges"""        converged = False        if self.prevgrid != None:            prevacc = 0.0            curracc = 0.0            for pr, cr in zip(self.prevgrid, self.grid):                for pc, cc in zip(pr, cr):                    prevacc += pc.maxQ()[0]                    curracc += cc.maxQ()[0]            if abs(curracc - prevacc) < self.config["threshold_difference"]:                converged = True        return self.iteration_count < self.config["max_iterations"] and not converged    def inBounds(self, r, c):        height, width = self.config["map_size"]        if   r >= height or r < 0:            return False        elif c >= width  or c < 0:            return False        return True    def getCell(self, r, c):        return self.grid[r][c]    def maker(self, action, currQ):        wall_reward = self.config["reward_for_hitting_wall"]        discount = self.config["discount_factor"]        learnRate = self.config["learning_rate"]        if not self.inBounds(*action):            toret = wall_reward + discount * currQ.maxQ()[0]        else:            cellNew = self.getCell(*action)            if cellNew.getType() == "WALL":                toret = wall_reward + discount * currQ.maxQ()[0]            else:                toret = cellNew.getReward() + discount * cellNew.maxQ()[0]        return toret    def iterate(self):        self.iteration_count += 1        to_return = PolicyList()        policy_data = list()        p_forward = self.config["prob_move_forward"]        p_backward = self.config["prob_move_backward"]        p_left = self.config["prob_move_left"]        p_right = self.config["prob_move_right"]        wall_reward = self.config["reward_for_hitting_wall"]        discount = self.config["discount_factor"]        for ri, row in enumerate(self.grid):            for ci, cell in enumerate(row):                toAdd = Qs()                toAdd.copy(cell)                currType = cell.getType()                if currType == "WALL" or \                   currType == "PIT"  or \                   currType == "GOAL":                    newgrid[ri][ci] = toAdd                    policy_data.append(currType)                    continue                nswe = self.northSouthWestEast(ri, ci)                rvgN = self.maker(nswe["N"], cell)                rvgS = self.maker(nswe["S"], cell)                rvgW = self.maker(nswe["W"], cell)                rvgE = self.maker(nswe["E"], cell)                qN   = p_forward * rvgN +  \                       p_backward * rvgS +  \                       p_left * rvgW +  \                       p_right * rvgE                qS   = p_forward * rvgS +  \                       p_backward * rvgN +  \                       p_left * rvgE +  \                       p_right * rvgW                qW   = p_forward * rvgW +  \                       p_backward * rvgE +  \                       p_left * rvgS +  \                       p_right * rvgN                qE   = p_forward * rvgE +  \                       p_backward * rvgW +  \                       p_left * rvgN +  \                       p_right * rvgS                toAdd.qNSWE = [qN, qS, qW, qE]                newgrid[ri][ci] = toAdd                policy_data.append(toAdd.maxQ()[1])        to_return.data = policy_data        return to_return